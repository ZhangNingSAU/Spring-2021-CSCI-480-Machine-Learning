{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527fd7a8",
   "metadata": {},
   "source": [
    "# CSCI 480\n",
    "# Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
    "\n",
    "+ ANNs are at the very core of Deep Learning.\n",
    "+ ideal to tackle large and highly complex Machine Learning tasks\n",
    "    - classifying billions of images (e.g., Google Images)\n",
    "    - powering speech recogni‐ tion services (e.g., Apple’s Siri)\n",
    "    - recommending the best videos to watch to hundreds of millions of users every day (e.g., YouTube)\n",
    "    - learning to beat the world champion at the game of Go by playing millions of games against itself (DeepMind’s Alpha‐ Zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c62a42f",
   "metadata": {},
   "source": [
    "## From Biological to Artificial Neurons\n",
    "+ In 1943, in their paper [A Logical Calculus of Ideas Immanent in Nervous Activity](https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf), the neurophysiologist Warren McCulloch and the mathematician Walter Pitts presented a simplified computational model of how biological neurons might work together in animal brains to perform complex computations using propositional logic.\n",
    "+ ANN waves\n",
    "\n",
    "![ANN waves](https://www.researchgate.net/profile/David-Macedo-4/publication/330838896/figure/fig1/AS:722098146246656@1549173022089/The-three-historical-waves-of-artificial-neural-networks-research-GOODFELLOW-BENGIO.png)\n",
    "\n",
    "+ Why ANN came back agian and will last long?\n",
    "    - There is now a huge quantity of data available to train neural networks, and ANNs frequently outperform other ML techniques on very large and complex problems.\n",
    "    - The tremendous increase in computing power since the 1990s now makes it pos‐ sible to train large neural networks in a reasonable amount of time. This is in part due to Moore’s Law, but also thanks to the gaming industry, which has pro‐ duced powerful GPU cards by the millions.\n",
    "    - The training algorithms have been improved. To be fair they are only slightly dif‐ ferent from the ones used in the 1990s, but these relatively small tweaks have a huge positive impact.\n",
    "    - Some theoretical limitations of ANNs have turned out to be benign in practice. For example, many people thought that ANN training algorithms were doomed because they were likely to get stuck in local optima, but it turns out that this is rather rare in practice (or when it is the case, they are usually fairly close to the global optimum).\n",
    "    - ANNs seem to have entered a virtuous circle of funding and progress. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cef4e87",
   "metadata": {},
   "source": [
    "## Biological Neurons\n",
    "![Biological Neurons](https://upload.wikimedia.org/wikipedia/commons/1/10/Blausen_0657_MultipolarNeuron.png)\n",
    "\n",
    "## Biological Neuron Network\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Cajal_actx_inter.jpg/300px-Cajal_actx_inter.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df170e",
   "metadata": {},
   "source": [
    "## Logical Computations with Neurons\n",
    "+ artificial neuron: a very simple model of the biological neuron\n",
    "    - C = A\n",
    "    - C = A and B\n",
    "    - C = A or B\n",
    "    - C = not B (if A is active all the time) \n",
    "\n",
    "![Logical Computations with Neurons](https://www.oreilly.com/library/view/neural-networks-and/9781492037354/assets/mlst_1003.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf16f8",
   "metadata": {},
   "source": [
    "## The Perceptron (Single-layer Perceptron)\n",
    "+ based on `threshold logic unit (TLU)`\n",
    "\n",
    "![](../Resources/ch10-perceptron.png)\n",
    "\n",
    "+ The TLU computes a weighted sum of its inputs\n",
    "    \n",
    "    $$z = w_1 x_1 + w_2 x_2 + \\ldots + w_n x_n = x^T w$$\n",
    "    \n",
    "+ then applies a step function to that sum and outputs the result: \n",
    "    \n",
    "    $$\n",
    "    h_w(x) = step(z), where z = x^T w.\n",
    "    $$\n",
    "    \n",
    "    - Step function\n",
    "   $$ heaviside(z)=   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      0 &  if \\space z \\lt 0 \\\\\n",
    "      1 &  if \\space z \\ge 0 \\\\\n",
    "\\end{array} \n",
    "\\right.  $$\n",
    "\n",
    "    - or\n",
    "\n",
    "   $$ sgn(z)=   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      -1 &  if \\space z \\lt 0 \\\\\n",
    "      0 &  if \\space z = 0 \\\\\n",
    "      1 &  if \\space z \\gt 0 \\\\\n",
    "\\end{array} \n",
    "\\right.  $$\n",
    "\n",
    "+ A Perceptron is simply composed of a single layer of TLUs, with each TLU connected to all the inputs.\n",
    "    - When all the neurons in a layer are connected to every neuron in the previous layer (i.e., its input neurons), it is called a fully connected layer or a dense layer. \n",
    "\n",
    "    ![](../Resources/ch10-perceptron2.png)\n",
    "\n",
    "    - compute the outputs of a layer of artificial neurons for several instances at once\n",
    "        + X represents the matrix of input features. It has one row per instance, one column per feature.\n",
    "        + The weight matrix W contains all the connection weights except for the ones from the bias neuron.\n",
    "        + The bias vector b contains all the connection weights between the bias neuron and the artificial neurons.\n",
    "        + The function φ is called the activation function. when the artificial neurons are TLUs, it is a step function.\n",
    "    $$h_{W,b} = \\phi(XW+b)$$\n",
    "    \n",
    "+ Perceptron learning rule: Hebb’s rule\n",
    "    - the connection weight between two neurons is increased whenever they have the same output. \n",
    "    $$w_{i,j}^{(next step)} = w_{i,j} + \\eta (y_j - \\hat{y}_j)x_i$$\n",
    "    \n",
    "       + $w_{i,j}$ is the connection weight between the $i^{th}$ input neuron and the $j^{th}$ output neuron.\n",
    "       + $x_i$ is the $i^{th}$ input value of the current training instance.\n",
    "       + $\\hat{y}_j$ is the output of the $j^{th}$ output neuron for the current training instance.\n",
    "       + $y_j$ is the target output of the $j^{th}$ output neuron for the current training instance.\n",
    "       + $\\eta$ is the learning rate.\n",
    "  \n",
    "+ Note: Perceptron is incaple of learning complex patterns (e.g., the data can not be separated by linear boundaries). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac09b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e26a5d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int32) # Iris Setosa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2208b9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd784de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfff4d1",
   "metadata": {},
   "source": [
    "### Perceptron vs Stochastic Gradient Descent\n",
    "+ Perceptron learning algorithm strongly resembles Stochastic Gradient Descent.\n",
    "+ In fact, Scikit-Learn’s Perceptron class is equivalent to using an SGDClassifier with the following hyperparameters: loss=\"perceptron\", learning_rate=\"constant\", eta0=1 (the learning rate), and penalty=None (no regu‐ larization).\n",
    "### Perceptron vs Logistic Regression\n",
    "+ Perceptrons do not output a class probability.\n",
    "+ This is one of the good reasons to prefer Logistic Regression over Perceptrons.\n",
    "### Weaknesses of Perceptrons\n",
    "+ incapable of solving some trivial problems (e.g., the Exclusive OR (XOR) classification problem\n",
    "\n",
    "![OR VS XOR](https://res.cloudinary.com/practicaldev/image/fetch/s--NK5uRtLC--/c_imagga_scale,f_auto,fl_progressive,h_900,q_auto,w_1600/https://dev-to-uploads.s3.amazonaws.com/i/lkli02223oqhlac1jetz.png)\n",
    "\n",
    "![xor](https://i1.wp.com/www.tech-quantum.com/wp-content/uploads/2019/03/XOR-Problem.png?fit=800%2C451&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f754b5",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron and Backpropagation\n",
    "+ An MLP is composed of one (passthrough) input layer, one or more layers of TLUs, called hidden layers, and one final layer of TLUs called the output layer.\n",
    "\n",
    "![](../Resources/ch10-mlp.png)\n",
    "\n",
    "+ When an ANN contains a deep stack of hidden layers8, it is called a deep neural net‐ work (DNN).\n",
    "\n",
    "### Backpropagation: a way to train MLPs\n",
    "+ simply Gradient Descent using an efficient technique for computing the gradients automatically in just two passes through the network (one forward, one backward)\n",
    "+ the backpropagation algo‐ rithm is able to compute the gradient of the network’s error with regards to every sin‐ gle model parameter.\n",
    "+ In other words, it can find out how each connection weight and each bias term should be tweaked in order to reduce the error.\n",
    "\n",
    "+ `Backpropagation Algorithm`\n",
    "    - It handles one `mini-batch` at a time, and it goes through the full training set multiple times. Each pass is called an epoch.\n",
    "    - `forward pass`: mini-batch -> input layer -> hidden layer(s) -> output layer. it is exactly like making predictions, except all intermediate results are preserved since they are needed for the backward pass.\n",
    "    - Next, the algorithm measures the network’s output error (compare the output with the target: $y$ vs $\\hat{y}$)\n",
    "    - Then it computes how much each output connection contributed to the error analytically by simply applying the [`chain rule`](https://en.wikipedia.org/wiki/Chain_rule).\n",
    "    - `backward pass`: The algorithm then measures how much of these error contributions came from each connection in the layer below, again using the chain rule, by propagating the error gradient backward through the network.\n",
    "    - Finally, the algorithm performs a Gradient Descent step to tweak all the connec‐ tion weights in the network, using the error gradients it just computed.\n",
    "\n",
    "+ Summary\n",
    "\n",
    "`This algorithm is so important, it’s worth summarizing it again: for each training instance the backpropagation algorithm first makes a prediction (forward pass), measures the error, then goes through each layer in reverse to measure the error con‐ tribution from each connection (reverse pass), and finally slightly tweaks the connec‐ tion weights to reduce the error (Gradient Descent step).`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a88843a",
   "metadata": {},
   "source": [
    "### Activation functions for MLPs with Backpropagation\n",
    "+ replace step function with\n",
    "   - logistic function\n",
    "   $$\n",
    "   \\sigma(z) = \\dfrac{1}{1+exp(-z)}\n",
    "   $$\n",
    "   - hyperbolic tangent function \n",
    "   $$\n",
    "       tanh(z) = 2\\sigma(2z)-1\n",
    "   $$\n",
    "   - Rectified Linear Unit function(ReLU is one of the most commonly used activation function in deep learning):\n",
    "   $$\n",
    "   ReLU(z) = max(0, z)\n",
    "   $$\n",
    "   \n",
    " \n",
    "![activation functions and their derivatives](https://www.oreilly.com/library/view/neural-networks-and/9781492037354/assets/mlst_1008.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f6e99",
   "metadata": {},
   "source": [
    "## Regression MLPs\n",
    "+ If you want to predict a single value, you just need a single output neuron.\n",
    "+ For multivariate regression, you need one output neuron per output dimension.\n",
    "+ In general, when building an MLP for regression, you do not want to use any activa‐ tion function for the output neurons, so they are free to output any range of values.\n",
    "+ However, if you want to guarantee that the output will always be positive, then you can use the ReLU activation function, or the softplus activation function in the output layer.\n",
    "+ Finally, if you want to guarantee that the predictions will fall within a given range of values, then you can use the logistic function or the hyperbolic tangent, and scale the labels to the appropriate range: 0 to 1 for the logistic function, or –1 to 1 for the hyperbolic tangent.\n",
    "+ The loss function to use during training is typically the `mean squared error`, but if you have a lot of outliers in the training set, you may prefer to use the `mean absolute error` instead. Alternatively, you can use the `Huber loss`, which is a combination of both.\n",
    "+ Typical Regression MLP Architecture\n",
    "\n",
    "|Hyperparameter|Typical Value|\n",
    "|---|---|\n",
    "|# input neurons|One per input feature (e.g., 28 x 28 = 784 for MNIST)|\n",
    "|# hidden layers|Depends on the problem. Typically 1 to 5.|\n",
    "|# neurons per hidden layer|Depends on the problem. Typically 10 to 100.|\n",
    "|# output neurons|1 per prediction dimension|\n",
    "|Hidden activation|ReLU (or SELU, see Chapter 11)|\n",
    "|Output activation|None or ReLU/Softplus (if positive outputs) or Logistic/Tanh (if bounded outputs)|\n",
    "|Loss function|MSE or MAE/Huber (if outliers)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1851af2",
   "metadata": {},
   "source": [
    "## Classification MLPs\n",
    "+ For a binary classification problem, you just need a single output neuron using the logistic activation function.\n",
    "+ MLPs can also easily handle multilabel binary classification tasks. In this case, you would need multiple output neurons, both using the logistic activation function.\n",
    "+ For a multiclass classification problem, you need to have one output neuron per class, and you should use the softmax activation function for the whole output layer.\n",
    "\n",
    "![](../Resources/ch10-multiclass.png)\n",
    "\n",
    "+ Typical Classification MLP Architecture\n",
    "\n",
    "|Hyperparameter|Binary classification|Multilabel binary classification|Multiclass classification|\n",
    "|---|---|---|---|\n",
    "|Input and hidden layers|Same as regression|Same as regression|Same as regression|\n",
    "|# output neurons|1|1 per label|1 per class|\n",
    "|Output layer activation|logistic|logistic|softmax|\n",
    "|loss function|Cross-Entropy|Cross-Entropy|Cross-Entropy|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669ce33a",
   "metadata": {},
   "source": [
    "## Implementing MLPs with Keras\n",
    "+ [Keras](https://keras.io) is a high-level Deep Learning API that allows you to easily build, train, evaluate and execute all sorts of neural networks.\n",
    "+ Two Keras implementations: Keras-team and tf.keras(keras in Tensorflow, we will use tf.keras in our class)\n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQYKhfHmW84jKHAm10LlWV5pmtSTMuh91dUs2wIGS--8LEYf20576nbN0YZM5OyfK2kV68&usqp=CAU)\n",
    "\n",
    "### Installing TensorFlow 2\n",
    "~~~~\n",
    "python3 -m pip install --upgrade tensorflow\n",
    "~~~~\n",
    "For GPU support, you need to install `tensorflow-gpu` instead of `tensorflow`, and there are other libraries to install. See https://tensorflow.org/install/gpu for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e22f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d57d762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version:  2.4.1\n",
      "keras version:  2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorflow version: \", tf.__version__)\n",
    "# Note that it ends with -tf, highlighting the fact that tf.keras implements the Keras API, plus some extra TensorFlow-specific features.\n",
    "print(\"keras version: \", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a131d37d",
   "metadata": {},
   "source": [
    "### Building an Image Classifier Using the Sequential API\n",
    "#### Using Keras to Load the Dataset\n",
    "+ the images represent fashion items rather than handwritten digits, so each class is more diverse and the problem turns out to be significantly more challenging than MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6b41409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4b732",
   "metadata": {},
   "source": [
    "+ since we are going to train the neural network using Gradient Descent, we must scale the input features.\n",
    "+ For simplicity, we just scale the pixel intensities down to the 0-1 range by dividing them by 255.0(this also converts them to floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b66bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c4b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "                   \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e0d90d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63890447",
   "metadata": {},
   "source": [
    "![fashion mnist example](https://www.researchgate.net/profile/Saeed-Reza-Kheradpisheh/publication/342801790/figure/fig2/AS:911232181735425@1594266090934/Sample-images-from-Fashion-MNIST-dataset.png)\n",
    "#### Creating the Model Using the Sequential API\n",
    "+ Line 1 (of the next cell): creates a Sequential model, a neural network that is just composed of a single stack of layers, connected sequentially. \n",
    "+ Line 2: builds the first layer and add it to the model. `Flatten` converts each input image into a 1D array.\n",
    "+ Line 3: adds a Dense hidden layer with 300 neurons, and uses the ReLU activation function. \n",
    "    - Each Dense layer manages its own weight matrix\n",
    "    - It also manages a vector of bias terms (one per neuron).\n",
    "    - For other activation functions, see https://keras.io/activations/\n",
    "+ Line 4: adds a second Dense hidden layer with 100 neurons, also uses the ReLU activation function.\n",
    "+ Line 5: adds a Dense output layer with 10 neurons (one per class), using the softmax activation function(this is a multiclass classification problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffcd42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e7148b",
   "metadata": {},
   "source": [
    "+ We can also combine the code above in one statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d01bb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dense(300, activation=\"relu\"),\n",
    "        keras.layers.Dense(100, activation=\"relu\"),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48feec5a",
   "metadata": {},
   "source": [
    "+ The model’s summary() method displays all the model’s layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "015c9061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516b971",
   "metadata": {},
   "source": [
    "+ You can easily get a model’s list of layers, to fetch a layer by its index, or you can fetch it by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8181b2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x13e2e4d00>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x13ed84220>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x13dfb6cd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x13dfb66d0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3858208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "703202ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3').name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de90d4a5",
   "metadata": {},
   "source": [
    "+ All the parameters of a layer can be accessed using its get_weights() and set_weights() method. For a Dense layer, this includes both the connection weights and the bias terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e4e4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e9bcca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06429768, -0.06606724,  0.02467071, ..., -0.05313261,\n",
       "        -0.04990781,  0.01793566],\n",
       "       [-0.02394059, -0.02384443, -0.02873898, ...,  0.00780939,\n",
       "        -0.01034213,  0.05872054],\n",
       "       [-0.05016194, -0.06758564, -0.01342009, ...,  0.04782038,\n",
       "         0.04958003,  0.03458665],\n",
       "       ...,\n",
       "       [ 0.03488541,  0.01060686,  0.03757443, ..., -0.02286218,\n",
       "         0.05683467,  0.0406133 ],\n",
       "       [ 0.02074627,  0.04259919,  0.00565634, ..., -0.00015141,\n",
       "        -0.05520375,  0.01094227],\n",
       "       [ 0.03369625,  0.03859156,  0.05131359, ..., -0.02671528,\n",
       "         0.00513736, -0.05501113]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "057725ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3cf74d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65d9a818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f91c3a",
   "metadata": {},
   "source": [
    "+ Notice that the Dense layer initialized the connection weights randomly (which is needed to break symmetry, as we discussed earlier), and the biases were just initial‐ ized to zeros, which is fine. If you ever want to use a different initialization method, you can set kernel_initializer (kernel is another name for the matrix of connec‐ tion weights) or bias_initializer when creating the layer. We will discuss initializ‐ ers further in Chapter 11, but if you want the full list, see https://keras.io/initializers/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4966c5f9",
   "metadata": {},
   "source": [
    "#### Compiling the Model\n",
    "+ After a model is created, you must call its compile() method to specify the loss func‐ tion and the optimizer to use. Optionally, you can also specify a list of extra metrics to compute during training and evaluation:\n",
    "+ For other losses, see https://keras.io/losses/\n",
    "    - If the labels are `sparse`: `[0,1,2,3,4,5,6,7,8,9]`, we use sparse_categorical_crossentropy.\n",
    "    - If the labels are `one-hot-encoded`, we use `categorical_crossentropy`.\n",
    "    - If we do `binary classification` (with one or more binary labels), then we would use the \"sigmoid\" (i.e., logistic) activation function in the output layer instead of the \"softmax\" activation function, we use `binary_crossentropy`.\n",
    "+ For other optimizers, see https://keras.io/optimizers/ \n",
    "+ For other metrics, see https://keras.io/metrics/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07ec2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=\"sgd\",\n",
    "                  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99d7a3",
   "metadata": {},
   "source": [
    "#### Training and Evaluating the Model\n",
    "+ train the model on the training set\n",
    "+ also use the validation set to detect the potential overfitting(the performance on the training set is much better than on the validation set) or some bug(e.g.,a data mis‐ match between the training set and the validation set)\n",
    "+ At each epoch during training, Keras displays the number of instances processed so far (along with a progress bar), the mean training time per sample, the loss and accuracy (or any other extra metrics you asked for), both on the training set and the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27491079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.9840 - accuracy: 0.7014 - val_loss: 0.5204 - val_accuracy: 0.8170\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4990 - accuracy: 0.8264 - val_loss: 0.4380 - val_accuracy: 0.8478\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4501 - accuracy: 0.8439 - val_loss: 0.4181 - val_accuracy: 0.8586\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4247 - accuracy: 0.8516 - val_loss: 0.3852 - val_accuracy: 0.8706\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3981 - accuracy: 0.8598 - val_loss: 0.3834 - val_accuracy: 0.8716\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3788 - accuracy: 0.8647 - val_loss: 0.3637 - val_accuracy: 0.8762\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3605 - accuracy: 0.8733 - val_loss: 0.3648 - val_accuracy: 0.8724\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3574 - accuracy: 0.8732 - val_loss: 0.3585 - val_accuracy: 0.8764\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3409 - accuracy: 0.8791 - val_loss: 0.3456 - val_accuracy: 0.8802\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3347 - accuracy: 0.8806 - val_loss: 0.3517 - val_accuracy: 0.8814\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3265 - accuracy: 0.8837 - val_loss: 0.3371 - val_accuracy: 0.8856\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3115 - accuracy: 0.8875 - val_loss: 0.3285 - val_accuracy: 0.8882\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3110 - accuracy: 0.8878 - val_loss: 0.3190 - val_accuracy: 0.8864\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3012 - accuracy: 0.8903 - val_loss: 0.3267 - val_accuracy: 0.8866\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2955 - accuracy: 0.8936 - val_loss: 0.3180 - val_accuracy: 0.8874\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2908 - accuracy: 0.8939 - val_loss: 0.3201 - val_accuracy: 0.8866\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2825 - accuracy: 0.8975 - val_loss: 0.3142 - val_accuracy: 0.8904\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2773 - accuracy: 0.9009 - val_loss: 0.3057 - val_accuracy: 0.8894\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2697 - accuracy: 0.9008 - val_loss: 0.3122 - val_accuracy: 0.8872\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2710 - accuracy: 0.9033 - val_loss: 0.3196 - val_accuracy: 0.8864\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2635 - accuracy: 0.9039 - val_loss: 0.3096 - val_accuracy: 0.8880\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2538 - accuracy: 0.9092 - val_loss: 0.3035 - val_accuracy: 0.8886\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2546 - accuracy: 0.9081 - val_loss: 0.2978 - val_accuracy: 0.8928\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2507 - accuracy: 0.9098 - val_loss: 0.3083 - val_accuracy: 0.8882\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2409 - accuracy: 0.9136 - val_loss: 0.3139 - val_accuracy: 0.8854\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2395 - accuracy: 0.9131 - val_loss: 0.2940 - val_accuracy: 0.8936\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2340 - accuracy: 0.9168 - val_loss: 0.2953 - val_accuracy: 0.8928\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2272 - accuracy: 0.9191 - val_loss: 0.2877 - val_accuracy: 0.8944\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2197 - accuracy: 0.9217 - val_loss: 0.2922 - val_accuracy: 0.8918\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2228 - accuracy: 0.9213 - val_loss: 0.3080 - val_accuracy: 0.8888\n"
     ]
    }
   ],
   "source": [
    "# the defaut batch_size is 32: batch_size=32\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8f215",
   "metadata": {},
   "source": [
    "+ If the training set was very skewed, with some classes being overrepresented and oth‐ ers underrepresented, it would be useful to set the class_weight argument when calling the fit() method, giving a larger weight to underrepresented classes, and a lower weight to overrepresented classes. These weights would be used by Keras when computing the loss.\n",
    "+ If you need per-instance weights instead, you can set the sam ple_weight argument (it supersedes class_weight). This could be useful for exam‐ ple if some instances were labeled by experts while others were labeled using a crowdsourcing platform: you might want to give more weight to the former.\n",
    "+ You can also provide sample weights (but not class weights) for the validation set by adding them as a third item in the validation_data tuple.\n",
    "\n",
    "+ The fit() method returns a History object containing \n",
    "    - the training parameters (his tory.params)\n",
    "    - the list of epochs it went through (history.epoch)\n",
    "    - and most impor‐ tantly a dictionary (history.history) containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6aef66af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a93a7",
   "metadata": {},
   "source": [
    "+ If you are not satisfied with the performance of your model, you should go back and tune the model’s hyperparameters\n",
    "    - the number of layers\n",
    "    - the number of neurons per layer\n",
    "    - the types of activation functions we use for each hidden layer\n",
    "    - the number of training epochs\n",
    "    - the batch size\n",
    "    \n",
    "+ Once you are satisfied with your model’s validation accuracy, you should evaluate it on the test set to estimate the generalization error before you deploy the model to production. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d624c09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 76.0464 - accuracy: 0.8307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[76.0464096069336, 0.8306999802589417]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaa2dac",
   "metadata": {},
   "source": [
    "#### Using the Model to Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69fa96a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[:5]\n",
    "y_proba = model.predict(X_new)\n",
    "print(y_proba.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3221bfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.argmax(y_proba, axis=-1)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f20bd2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.3  0.   0.67 0.   0.03 0.   0.   0.  ]\n",
      " [0.94 0.   0.   0.   0.   0.   0.06 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.85 0.   0.15]]\n"
     ]
    }
   ],
   "source": [
    "X_new = X_train[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "print(y_proba.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "199be8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 7]\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.argmax(y_proba, axis=-1)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643a41e",
   "metadata": {},
   "source": [
    "### Building a Regression MLP Using the Sequential API\n",
    "+ Building, training, evaluating and using a regression MLP using the Sequential API to make predictions is quite similar to what we did for classification.\n",
    "+ The main differ‐ ences are the fact that the output layer has a single neuron (since we only want to predict a single value) and uses no activation function.\n",
    "+ and the loss function is the mean squared error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df27cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74f7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '.' => save the data in the current folder, you can also specify your own location\n",
    "housing = fetch_california_housing(data_home='.')\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a263b63",
   "metadata": {},
   "source": [
    "+ Since the dataset is quite noisy, we just use a single hidden layer with fewer neurons than before, to avoid overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "591c61d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.4172 - val_loss: 0.5982\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6075 - val_loss: 0.4742\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4861 - val_loss: 0.4954\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5161 - val_loss: 0.4435\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4735 - val_loss: 0.4345\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4492 - val_loss: 0.4222\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4434 - val_loss: 0.4161\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4623 - val_loss: 0.4203\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4308 - val_loss: 0.4102\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4099 - val_loss: 0.4110\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4100 - val_loss: 0.4042\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4203 - val_loss: 0.4006\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4151 - val_loss: 0.3978\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4120 - val_loss: 0.3956\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4047 - val_loss: 0.4192\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5273 - val_loss: 0.3937\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3993 - val_loss: 0.3889\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4064 - val_loss: 0.3837\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3990 - val_loss: 0.3818\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3995 - val_loss: 0.3893\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "        keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20,\n",
    "                        validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd32ac5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3854\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a17e0b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.404094 ]\n",
      " [2.5365233]\n",
      " [3.8159509]]\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[:3] # pretend these are new instances\n",
    "\n",
    "y_pred = model.predict(scaler.transform(X_new))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dd1be4",
   "metadata": {},
   "source": [
    "# Building Complex/non-sequential Models Using the Functional API\n",
    "+ [Reference Paper](https://arxiv.org/abs/1606.07792)\n",
    "+ It connects all or part of the inputs directly to the output layer\n",
    "    - This architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path).\n",
    "    - A regular MLP forces all the data to flow through the full stack of layers, thus simple patterns in the data may end up being distorted by this sequence of transfor‐ mations.\n",
    "    \n",
    "![ch10-wide.png](../Resources/ch10-wide.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ec9d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to create an Input object.\n",
    "input = keras.layers.Input(shape=X_train.shape[1:])\n",
    "# Next, we create a Dense layer with 30 neurons and using the ReLU activation function. As soon as it is created, notice that we call it like a function, passing it the input. This is why this is called the Functional API.\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input)\n",
    "# We then create a second hidden layer, and again we use it as a function.\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "# Next, we create a Concatenate() layer, and once again we immediately use it like a function, to concatenate the input and the output of the second hidden layer\n",
    "concat = keras.layers.Concatenate()([input, hidden2])\n",
    "# Then we create the output layer, with a single neuron and no activation function.\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "# Lastly, we create a Keras Model, specifying which inputs and outputs to use.\n",
    "model = keras.models.Model(inputs=[input], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0cc5b",
   "metadata": {},
   "source": [
    "+ First, we need to create an Input object.\n",
    "+ Next, we create a Dense layer with 30 neurons and using the ReLU activation function. As soon as it is created, notice that we call it like a function, passing it the input. This is why this is called the Functional API.\n",
    "+ We then create a second hidden layer, and again we use it as a function.\n",
    "+ Next, we create a Concatenate() layer, and once again we immediately use it like a function, to concatenate the input and the output of the second hidden layer\n",
    "+ Then we create the output layer, with a single neuron and no activation function.\n",
    "+ Lastly, we create a Keras Model, specifying which inputs and outputs to use.\n",
    "#### Once you have built the Keras model, everything is exactly like earlier, so no need to repeat it here: you must compile the model, train it, evaluate it and use it to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b67b7fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3031 - val_loss: 4.6872\n",
      "Epoch 2/4\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5921 - val_loss: 4.4882\n",
      "Epoch 3/4\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2776 - val_loss: 1.4511\n",
      "Epoch 4/4\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.5942 - val_loss: 0.5185\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=4,\n",
    "                        validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7608b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4857\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4b390da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5826242]\n",
      " [2.16786  ]\n",
      " [3.5506988]]\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[:3] # pretend these are new instances\n",
    "\n",
    "y_pred = model.predict(scaler.transform(X_new))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604fc8d",
   "metadata": {},
   "source": [
    "+ What if you want to send a subset of the features through the wide path, and a different subset (possibly overlapping) through the deep path?\n",
    "\n",
    "![wide2](../Resources/ch10-wide2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3cd6f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5]) # features 0-4\n",
    "input_B = keras.layers.Input(shape=[6]) # features 2-7\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5eeda21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10781c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train_scaled[:, :5], X_train_scaled[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid_scaled[:, :5], X_valid_scaled[:, 2:]\n",
    "X_test_A, X_test_B = X_test_scaled[:, :5], X_test_scaled[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "449e876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                        validation_data=((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a57d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel3.9",
   "language": "python",
   "name": "kernel3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
